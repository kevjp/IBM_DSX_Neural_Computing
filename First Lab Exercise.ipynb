{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<pyspark.sql.session.SparkSession object at 0x7f4db91c9470>\n<SparkContext master=spark://yp-spark-dal09-env5-0040:7088 appName=PySparkShell>\n"
                }
            ], 
            "source": "# predifined spark session\nprint(spark) \n# get the context\nsc = spark.sparkContext\nprint(sc)"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475\n"
                }
            ], 
            "source": "# Creat an RDD from a Python object in this process (the \"driver\").\n# The parallelize function  creating the \"numbers\" RDD\ndata = [1,2,3,4,5]\nfirstRDD = sc.parallelize(data)\nprint(firstRDD)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "PythonRDD[1] at RDD at PythonRDD.scala:48\n"
                }
            ], 
            "source": "# lambda function: x -> x+3\nRDD2 = firstRDD.map(lambda x:x+3)  \nprint(RDD2)\n# nothing happened to far, as there is no action"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "Py4JJavaError", 
                    "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 10 times, most recent failure: Lost task 0.9 in stage 0.0 (TID 12, yp-spark-dal09-env5-0019, executor 647ae8b4-9104-40b2-8a68-8c3e4c093f58): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 160, in main\n    func, profiler, deserializer, serializer = read_command(pickleSer, infile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 54, in read_command\n    command = serializer._read_with_length(file)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 169, in _read_with_length\n    return self.loads(obj)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 455, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 783, in _make_skel_func\n    closure = _reconstruct_closure(closures) if closures else None\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 775, in _reconstruct_closure\n    return tuple([_make_cell(v) for v in values])\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1981)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:956)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:381)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:955)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 160, in main\n    func, profiler, deserializer, serializer = read_command(pickleSer, infile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 54, in read_command\n    command = serializer._read_with_length(file)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 169, in _read_with_length\n    return self.loads(obj)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 455, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 783, in _make_skel_func\n    closure = _reconstruct_closure(closures) if closures else None\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 775, in _reconstruct_closure\n    return tuple([_make_cell(v) for v in values])\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-4-820984ddf558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \"count\" is an action and triggers the transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRDD2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \"\"\"\n\u001b[0;32m-> 1056\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \"\"\"\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 10 times, most recent failure: Lost task 0.9 in stage 0.0 (TID 12, yp-spark-dal09-env5-0019, executor 647ae8b4-9104-40b2-8a68-8c3e4c093f58): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 160, in main\n    func, profiler, deserializer, serializer = read_command(pickleSer, infile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 54, in read_command\n    command = serializer._read_with_length(file)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 169, in _read_with_length\n    return self.loads(obj)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 455, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 783, in _make_skel_func\n    closure = _reconstruct_closure(closures) if closures else None\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 775, in _reconstruct_closure\n    return tuple([_make_cell(v) for v in values])\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1981)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:956)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:381)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:955)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 160, in main\n    func, profiler, deserializer, serializer = read_command(pickleSer, infile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 54, in read_command\n    command = serializer._read_with_length(file)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 169, in _read_with_length\n    return self.loads(obj)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 455, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 783, in _make_skel_func\n    closure = _reconstruct_closure(closures) if closures else None\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/cloudpickle.py\", line 775, in _reconstruct_closure\n    return tuple([_make_cell(v) for v in values])\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "# \"count\" is an action and triggers the transformation   \na = RDD2.count() \nprint(a)"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[4, 5, 6, 7, 8]\n"
                }
            ], 
            "source": "a = RDD2.collect() \nprint(a)"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "DataFrame[age: bigint, name: string]\n"
                }
            ], 
            "source": "from pyspark.sql import Row\n\nlist = [('Anne',21),('Bob',22),('Carl',29),('Daisy',36)]\nrdd = sc.parallelize(list)\npeopleRDD = rdd.map(lambda x: Row(name=x[0], age=int(x[1]))) # Row generates a row object based on the column names name and age\npeopleDF = sqlContext.createDataFrame(peopleRDD) \nprint(peopleDF)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "rowCount": "500", 
                        "handlerId": "barChart", 
                        "valueFields": "age", 
                        "keyFields": "name", 
                        "aggregation": "SUM"
                    }
                }
            }, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFigure5521ab60\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                    \n                            <center><img style=\"max-width:initial !important\" src=\"data:image/png;base64,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\" class=\"pd_save\"></center>\n                        \n                    \n                \n        </div>\n    ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "import pixiedust\ndisplay(peopleDF)"
        }, 
        {
            "source": "# Lab 1 Solutions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "filePath = 'https://github.com/abisowri/test-Big-Data/blob/master/hamlet.txt'\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initalized for you.\n# The following variable contains the path to your file on your Object Storage.\npath_2 = bmos.url('BigDataModuleRyan', 'hamlet.txt')\n"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['Project Gutenberg Etext of Hamlet by Shakespeare',\n \"PG has multiple editions of William Shakespeare's Complete Works\",\n '']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "lines = sc.textFile(path_1)\nlines.take(3)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[['Project', 'Gutenberg', 'Etext', 'of', 'Hamlet', 'by', 'Shakespeare'],\n ['PG',\n  'has',\n  'multiple',\n  'editions',\n  'of',\n  'William',\n  \"Shakespeare's\",\n  'Complete',\n  'Works'],\n ['']]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "wordRDD = lines.flatMap(lambda x: x.split(' '))\nwordRDD.take(3)"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 27, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('Project', 1), ('Gutenberg', 1), ('Etext', 1), ('of', 1), ('Hamlet', 1)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "word1RDD = wordRDD.map(lambda x: (x, 1))\nword1RDD.take(5)"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 28, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('', 2290),\n ('fire!', 1),\n ('historical-pastoral,', 1),\n ('heedful', 1),\n ('Dead', 1),\n ('Custom', 1),\n ('evidence.', 1),\n ('matter;', 1),\n ('new-born', 1),\n ('bread;', 1)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "wordCountRDD = word1RDD.reduceByKey(lambda x,y: x+y )\nwordCountRDD.take(10)"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "Py4JJavaError", 
                    "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 13.0 failed 10 times, most recent failure: Lost task 1.9 in stage 13.0 (TID 84, yp-spark-dal09-env5-0021, executor 7f400459-64db-404d-89ed-a887a7815920): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 345, in func\n    return f(iterator)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1827, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:390)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 345, in func\n    return f(iterator)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1827, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:390)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mPy4JJavaError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-18-abaf6089d5a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mword1RDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordFilteredRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwordCountRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword1RDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mwordCountRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[1;32m/usr/local/src/spark21master/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark21master/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[1;31m# SparkContext#runJob.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m         \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark21master/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n", 
                        "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 13.0 failed 10 times, most recent failure: Lost task 1.9 in stage 13.0 (TID 84, yp-spark-dal09-env5-0021, executor 7f400459-64db-404d-89ed-a887a7815920): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 345, in func\n    return f(iterator)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1827, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:390)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 2408, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 345, in func\n    return f(iterator)\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1827, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\nTypeError: unhashable type: 'list'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:390)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "wordFilteredRDD = wordRDD.filter(lambda x: len(x)>0)\nword1RDD = wordFilteredRDD.map(lambda x: (x, 1))\nwordCountRDD = word1RDD.reduceByKey(lambda x,y: x+y )\nwordCountRDD.take(1)"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "dataframe"
                    }
                }
            }, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div><style type=\"text/css\" class=\"pd_save is-viewer-good\">\n  .df-table-wrapper .panel-heading {\n    border-radius: 0;\n    padding: 0px;\n  }\n  .df-table-wrapper .panel-heading:hover {\n    border-color: #008571;\n  }\n  .df-table-wrapper .panel-title a {\n    background-color: #f9f9fb;\n    color: #333333;\n    display: block;\n    outline: none;\n    padding: 10px 15px;\n    text-decoration: none;\n  }\n  .df-table-wrapper .panel-title a:hover {\n    background-color: #337ab7;\n    border-color: #2e6da4;\n    color: #ffffff;\n    display: block;\n    padding: 10px 15px;\n    text-decoration: none;\n  }\n  .df-table-wrapper {\n    font-size: small;\n    font-weight: 300;\n    letter-spacing: 0.5px;\n    line-height: normal;\n    height: inherit;\n    overflow: auto;\n  }\n  .df-table-search-count {\n    display: inline-block;\n    margin: 20px 0;\n  }\n  .df-table-container {\n    max-height: 50vh;\n    max-width: 100%;\n    overflow-x: auto;\n    position: relative;\n  }\n  .df-table-wrapper table {\n    border: 0 none #ffffff;\n    border-collapse: collapse;\n    margin: 0;\n    min-width: 100%;\n    padding: 0;\n    table-layout: fixed;\n    height: inherit;\n    overflow: auto;\n  }\n  .df-table-wrapper tr.hidden {\n    display: none;\n  }\n  .df-table-wrapper tr:nth-child(even) {\n    background-color: #f9f9fb;\n  }\n  .df-table-wrapper tr.even {\n    background-color: #f9f9fb;\n  }\n  .df-table-wrapper tr.odd {\n    background-color: #ffffff;\n  }\n  .df-table-wrapper td + td {\n    border-left: 1px solid #e0e0e0;\n  }\n\n  .df-table-wrapper thead,\n  .fixed-header {\n    color: #337ab7;\n    font-family: monospace;\n  }\n  .df-table-wrapper tr,\n  .fixed-row {\n    border: 0 none #ffffff;\n    margin: 0;\n    padding: 0;\n  }\n  .df-table-wrapper th,\n  .df-table-wrapper td,\n  .fixed-cell {\n    border: 0 none #ffffff;\n    margin: 0;\n    min-width: 50px;\n    padding: 5px 20px 5px 10px;\n    text-align: left;\n    word-wrap: break-word;\n  }\n  .df-table-wrapper th {\n    padding-bottom: 0;\n    padding-top: 0;\n  }\n  .df-table-wrapper th div {\n    max-height: 1px;\n    visibility: hidden;\n  }\n\n  .df-schema-field {\n    margin-left: 10px;\n  }\n\n  .fixed-header-container {\n    overflow: hidden;\n    position: relative;\n  }\n  .fixed-header {\n    border-bottom: 2px solid #2e6da4;\n    display: table;\n    position: relative;\n  }\n  .fixed-row {\n    display: table-row;\n  }\n  .fixed-cell {\n    display: table-cell;\n  }\n</style><div class=\"df-table-wrapper df-table-wrapper-8d7277a4 panel-group pd_save is-viewer-good\">\n  <!-- dataframe schema -->\n  \n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n        <a data-toggle=\"collapse\" href=\"#df-schema-8d7277a4\" data-parent=\"#df-table-wrapper-8d7277a4\">Schema</a>\n      </h4>\n    </div>\n    <div id=\"df-schema-8d7277a4\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\" style=\"font-family: monospace;\">\n        <div class=\"df-schema-type\">\n          <span>type: </span><span>struct</span>\n        </div>\n        <div class=\"df-schema-fields\">\n          <div>field:</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'long', 'name': 'count', 'nullable': True}</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'string', 'name': 'word', 'nullable': True}</div>\n          \n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <!-- dataframe table -->\n  <div class=\"panel panel-default\">\n    \n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n        <a data-toggle=\"collapse\" href=\"#df-table-8d7277a4\" data-parent=\"#df-table-wrapper-8d7277a4\">Table</a>\n      </h4>\n    </div>\n    \n    <div id=\"df-table-8d7277a4\" class=\"panel-collapse collapse in\">\n      <div class=\"panel-body\">\n        \n        <input type=\"text\" class=\"df-table-search form-control input-sm\" placeholder=\"Search table\">\n        <div>\n          <span class=\"df-table-search-count\">Showing 100 of 8603</span>\n        </div>\n        <!-- fixed header for when dataframe table scrolls -->\n        <div class=\"fixed-header-container\">\n          <div class=\"fixed-header\">\n            <div class=\"fixed-row\">\n              \n              \n              <div class=\"fixed-cell\">count</div>\n              \n              \n              \n              <div class=\"fixed-cell\">word</div>\n              \n              \n            </div>\n          </div>\n        </div>\n        <div class=\"df-table-container\">\n          <table class=\"df-table\">\n            <thead>\n              <tr>\n                \n                \n                <th><div>count</div></th>\n                \n                \n                \n                <th><div>word</div></th>\n                \n                \n              </tr>\n            </thead>\n            <tbody>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>fire!</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>historical-pastoral,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>heedful</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>Dead</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>Custom</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>evidence.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>matter;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>new-born</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>bread;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>dark</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>subject</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>journeys</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>imminent.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>maids</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>month,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>Dane;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>13</td>\n                \n                \n                \n                <td>do,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>spoken</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>loudly</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>action;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>Ophelia--</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>flame</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>wealth</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>3</td>\n                \n                \n                \n                <td>proof</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>impotence</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>Mess.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>5</td>\n                \n                \n                \n                <td>fall</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>didest</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>11</td>\n                \n                \n                \n                <td>why</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>clad,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>untimely</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>preceding</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>feet.]</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>neither.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>o'erreaches;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>looking</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>screen'd</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>side.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>5</td>\n                \n                \n                \n                <td>Get</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>daisies,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>Still</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>resulting</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>effect;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>soldier;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>windy</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>being:</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>there's</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>compulsive</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>daintier</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>wild</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>gilded</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>thanks:</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>18</td>\n                \n                \n                \n                <td>Laertes,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>lenten</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>cat</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>dir</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>3</td>\n                \n                \n                \n                <td>uses</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>rises.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>full,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>such,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>faithful</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>burden!</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>--Leave</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>About</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>female</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>dread</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>son.--</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>I;</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>You,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>glean,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>queen'?</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>bowl</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>70</td>\n                \n                \n                \n                <td>her</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>passeth</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>3</td>\n                \n                \n                \n                <td>Too</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>row</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>life,--</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>commandment:</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>bawdy</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>stirring.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>there.--Be</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>stoups</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>watchman</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>15</td>\n                \n                \n                \n                <td>believe</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>positively</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>allow'd.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>offence,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>further.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>Volt.</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>assur'd</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2</td>\n                \n                \n                \n                <td>profit</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>got</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>gentleman,</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>observation</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>wisely</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>observ'd</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>decayer</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>Away</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>proposer</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>1</td>\n                \n                \n                \n                <td>sin,</td>\n                \n                \n              </tr>\n              \n            </tbody>\n          </table>\n        </div>\n      </div>\n    </div>\n  </div>\n</div><script class=\"pd_save is-viewer-good\">\n  $(function() {\n    var tableWrapper = $('.df-table-wrapper-8d7277a4');\n    var fixedHeader = $('.fixed-header', tableWrapper);\n    var tableContainer = $('.df-table-container', tableWrapper);\n    var table = $('.df-table', tableContainer);\n    var rows = $('tbody > tr', table);\n    var total = 8603;\n\n    fixedHeader\n      .css('width', table.width())\n      .find('.fixed-cell')\n      .each(function(i, e) {\n        $(this).css('width', $('.df-table-wrapper-8d7277a4 th:nth-child(' + (i+1) + ')').css('width'));\n      });\n\n    tableContainer.scroll(function() {\n      fixedHeader.css({ left: table.position().left });\n    });\n\n    rows.on(\"click\", function(e){\n        var txt = e.delegateTarget.innerText;\n        var splits = txt.split(\"\\t\");\n        var len = splits.length;\n        var hdrs = $(fixedHeader).find(\".fixed-cell\");\n        // Add all cells in the selected row as a map to be consumed by the target as needed\n        var payload = {type:\"select\", targetDivId: \"\" };\n        for (var i = 0; i < len; i++) {\n          payload[hdrs[i].innerHTML] = splits[i];\n        }\n\n        //simple selection highlighting, client adds \"selected\" class\n        $(this).addClass(\"selected\").siblings().removeClass(\"selected\");\n        $(document).trigger('pd_event', payload);\n    });\n\n    $('.df-table-search', tableWrapper).keyup(function() {\n      var val = '^(?=.*\\\\b' + $.trim($(this).val()).split(/\\s+/).join('\\\\b)(?=.*\\\\b') + ').*$';\n      var reg = RegExp(val, 'i');\n      var index = 0;\n      \n      rows.each(function(i, e) {\n        if (!reg.test($(this).text().replace(/\\s+/g, ' '))) {\n          $(this).attr('class', 'hidden');\n        }\n        else {\n          $(this).attr('class', (++index % 2 == 0 ? 'even' : 'odd'));\n        }\n      });\n\n      $('.df-table-search-count', tableWrapper).html('Showing ' + index + ' of ' + total);\n    });\n  });\n\n  $(\".df-table-wrapper td:contains('http://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n  $(\".df-table-wrapper td:contains('https://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n</script>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "wordCountRows = wordCountRDD.map(lambda x: Row(word=x[0], count=int(x[1])))\nwordCountDF = sqlContext.createDataFrame(wordCountRows) \ndisplay(wordCountDF)"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 20, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['Project', 'Gutenberg', 'Etext']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import re\nwordRDD = lines.flatMap(lambda x: re.split('\\W+', x)) # apply re.split('\\W+', string) here\nwordFilteredRDD = wordRDD.filter(lambda x: len(x)>0) # do the filtering\nwordFilteredRDD.take(3)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 21, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('project', 1), ('gutenberg', 1), ('etext', 1)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "wordLowerRDD = wordFilteredRDD.map(lambda x: (x.lower(),1))\nwordLowerRDD.take(3)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('was', 88), ('incontinency', 1), ('rotten', 2)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "wordCountRDD = wordLowerRDD.reduceByKey(lambda x,y: x+y) # we can now get better word count results\nwordCountRDD.take(3)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 23, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('head', 27), ('law', 9), ('proof', 6)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#the trick here is to apply the lambda only to the second part of each item, i.e. x[1] \nfreqWordsRDD = wordCountRDD.filter(lambda x:  x[1] > 4 ) # tip: filter keeps the times where the lambda returns true.\nfreqWordsRDD.take(3)"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stopWordList = ['the','a','in','of','on','at','for','by','I','you','me'] \nstopWordsRDD = freqWordsRDD.filter(lambda x: x[0] in  stopWordList) # the 1st part of the tuple should be in the list "
        }, 
        {
            "source": "## 6) Better splitting \n\nCovered here because it needs to be at this position in the code. \nUse regular expressions for splitting the words.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import re\nwords = lines.flatMap(lambda x: re.split('\\W+',x))\nwords.collect"
        }, 
        {
            "source": "## 2) Use lower case\n\nModify the map call (4th line) to convert all strings to lower case (using `.lower()`).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "words1 = words.map(lambda x: (x.lower(), 1))"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wordCount = words1.reduceByKey(lambda x,y: x+y)"
        }, 
        {
            "source": "## 4) Filter rare words\n\nAdd a filtering step call remove all words with less than 5 occurrences. \n\nThis can be useful to identify common topics between documents, where very rare words can be misleading. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "freqWords = wordCount.filter(lambda x:  x[1] >= 5 )"
        }, 
        {
            "source": "## 5) List only stopwords\n\nAdd a filtering step to retain only words included in a list of stopwords. \n\nStopwords can be useful for recognising the style of an author. Removing stopwords can be useful in regocnising the topic of a document. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stopWordList = ['the','a','in','of','on','at','for','by','I','you','me'] \nstopWords = freqWords.filter(lambda x:  x[0] in stopWordList) "
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "of: 733\nat: 99\nin: 464\nby: 147\na: 582\nfor: 277\nthe: 1218\nme: 236\nyou: 610\non: 150\n"
                }
            ], 
            "source": "output = stopWords.collect()\nfor (word, count) in output:\n    print(\"%s: %i\" % (word, count))"
        }, 
        {
            "execution_count": 35, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "barChart"
                    }
                }
            }, 
            "outputs": [], 
            "source": "import pixiedust\ndf2 = sqlContext.createDataFrame(output)\ndisplay(df2)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}